# Q&A Chatbot with Ollama

This project implements a simple question-and-answer chatbot using the **Langchain Core**, **Streamlit**, and **Ollama** models. The chatbot allows users to ask questions, and the responses are generated using the Ollama language model. You can configure the chatbot parameters such as temperature and token limit from the sidebar.
![alt text](<Screenshot 2024-10-07 at 6.04.58 PM.png>)

## Features
- Select from different Ollama models for responses.
- Adjust temperature and token length to fine-tune the output.
- User-friendly interface powered by Streamlit.

## Requirements

Make sure you have the following dependencies installed:

- Python 3.12 or above
- `langchain_core`
- `langchain_community`
- `streamlit`
- `python-dotenv`

Install these dependencies by running the following:

```bash
pip install -r requirements.txt
